{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2FQSqHULRE94OesVOhP51",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sehwan1214/sehwan1214/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C824Id0uEuT"
      },
      "source": [
        "#**KNN**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. 분류와 회귀\n",
        "2. KNN의 개념\n",
        "3. KNN의 적용(Classification, Regression)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp61m3Ihucf0"
      },
      "source": [
        "##**1. 분류와 회귀**\n",
        "---\n",
        "\n",
        "* **분류(Classification)**\n",
        "\n",
        "\n",
        "* **회귀(Regression)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJGG7g4rvYy9"
      },
      "source": [
        "### **분류(Classification)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnzzPVQGvc_d"
      },
      "source": [
        "# 분류는 미리 정의된, 가능성 있는 여러 클래스 레이블중 하나를 예측하는 것\n",
        "# 주로 종속변수가 이름(숫자가 아님)\n",
        "# 두 개로만 나누는 Binary classification, 셋 이상의 클래스로 분류하는 Multiclass classification으로 나뉨\n",
        "# 분류 예시: 얼굴인식, 숫자 판별(MNIST), 스팸메일여부, 악성종양여부 등"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DYA40GywKdM"
      },
      "source": [
        "### **회귀(Regression)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrlex2nHwbOm"
      },
      "source": [
        "# 연속적인 숫자 또는 부동소수점수(실수)를 예측하는 것\n",
        "# 주로 종속변수가 숫자\n",
        "# 회귀 예시: 판매량 예측, 주가 예측, 온도 변화량 예측 등"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3THEVmDwl4F"
      },
      "source": [
        "##**2. KNN의 개념**\n",
        "---\n",
        "\n",
        "\n",
        "*   **KNN이란?**\n",
        "*   **KNN의 하이퍼파라미터(탐색할 이웃 수 k와 거리 측정 방법)**\n",
        "*   **KNN의 K가 가지는 의미**\n",
        "*   **KNN의 장단점 요약**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veAxyBRDRUHg"
      },
      "source": [
        "### **KNN이란?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJGjVVtKRqD5"
      },
      "source": [
        "# 주변 K개 자료의 class중 가장 많은 클래스로 특정 자료를 분류하는 방식 -> 투표 방식!\n",
        "# Training-data 자체가 모형일 뿐 어떠한 추정 방법도 모형도 없음 -> Wx + b 와 같은 모형이 존재x\n",
        "\n",
        "# 게으른 학습(lazy learner) 또는 사례중심학습(instance-based learning) <-> model-based learning : Wx + b(Linear Classification) -> W,b(parameter)추정\n",
        "# 게으른 학습: 알고리즘은 훈련 데이터에서 판별 함수(discrimination function = model-based learning)를 학습하는 대신 훈련 데이터 셋을 메로리에 저장하기 방법(instance-based learning)\n",
        "\n",
        "# 데이터의 차원이 증가하면 차원의 저주(curse of dimension) 문제가 발생 -> KNN은 차원이 증가할 수록 성능 저하가 심함 특히, Classification에서!\n",
        "# 거리추정방식: p=1 -> 맨하탄 거리, p=2 -> 유클리디언거리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iyv6uf3SBcW"
      },
      "source": [
        "### **KNN의 하이퍼파라미터(탐색할 이웃 수 k와 거리 측정 방법)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iXA9jwASFdQ"
      },
      "source": [
        "# k가 작을 경우(1-NN) -> 데이터의 지역적 특성을 지나치게 반영하여 즉, 너무 세세하게 나눠서 overfitting 발생\n",
        "# overfitting -> 새로 들어올 Data에 대한 대처를 할 수 없도록 되어버린 상태\n",
        "\n",
        "# k가 클 경우(50-NN) -> 학습 Data, Test Data에 대한 표현력이 감소하여 underfitting 발생\n",
        "\n",
        "# 학습을 통해 데이터의 경향성을 파악하는 것이 중요!, x - fitting은 모두 좋은 학습 결과가 아님!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD7iL57fUYDy"
      },
      "source": [
        "### **KNN의 K가 가지는 의미**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCLINpd_UZb-"
      },
      "source": [
        "# 새로운 자료에 대해 근접치 K의 개수에 따라 Group이 달리 분류된다\n",
        "# 다수결 방식(Majority voting): 이웃 범주 가운데 빈도 기준 제일 많은 범주로 새 데이터의 범주를 예측하는 것 -> K의 크기에 따라 New object의 class가 변경된다\n",
        "# 가중 합 방식(Weighted voting): 가까운 이웃의 정보에 좀 더 가중치를 부여 -> K의 크기와 상관없이 New object의 class는 불변이다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjOX2i0KU_qm"
      },
      "source": [
        "### **KNN의 장단점 요약**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D1ENd-XVeu7"
      },
      "source": [
        "# 장점\n",
        "# 노이즈의 영향을 크게 안 받음\n",
        "# 학습데이터 수가 많다면 꽤 효과적임\n",
        "# 데이터의 분산을 고려할 경우 매우 강건한 방법\n",
        "\n",
        "# 단점\n",
        "# 최적 이웃의 수(K)와 어떤 거리 척도(distance metric)가 분석에 적합한지 불분명해 데이터 각각의 특성에 맞게 연구자가 임의로 선정해야 함\n",
        "# 시간이 오래 걸림"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObTtE6l3V8bj"
      },
      "source": [
        "##**3. KNN의 적용**\n",
        "---\n",
        "\n",
        "*   **기계 학습의 일반적인 실습 순서**\n",
        "*   **Classification(분류)**    \n",
        "*   **Regression(회귀)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuMUED2mXEMU"
      },
      "source": [
        "####  **기계 학습의 일반적인 실습 순서**\n",
        "#### 1. 데이터셋 불러오기 -> seaborn 라이브러리 사용, 유명한 데이터 셋 대부분 지원(iris)\n",
        "#### 2. 데이터셋 카테고리의 실수화 -> setosa, versicolor, virginica : [0,1,2]\n",
        "#### 3. 데이터 분할 -> 학습데이터와 테스트 데이터로 나누기\n",
        "#### 4. 모형 추정 혹은 사례중심학습\n",
        "#### 5. 결과 분석 -> Confusion matrix로 확인\n",
        "#### 6. (옵션) 입력데이터의 표준화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYnK9OQ5YECd"
      },
      "source": [
        "### **Classification(분류)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sxm6QAk1sdg",
        "outputId": "2859ca2c-6b34-4a71-9b10-42634875ebdd"
      },
      "source": [
        "# 1. 데이터셋 불러오기\n",
        "\n",
        "import seaborn as sns # seaborn을 불러오고 sns로 축약함.\n",
        "iris = sns.load_dataset('iris') # Iris라는 변수명으로 Iris data를 download함\n",
        "print(iris.head()) #최초의 5개의 관측지를 print\n",
        "\n",
        "# ------------------------------------------------------------------------------#\n",
        "\n",
        "print(iris.shape) # iris data의 행과 열의 수\n",
        "x = iris.drop('species', axis=1) # 'species' 열을 drop하고 input x를 정의함 -> x: 입력데이터 즉, 입력변수\n",
        "print(x.shape)\n",
        "y = iris['species'] # 'species'열을 lavel y로 정의함 -> y: 라벨이자 타겟 즉, 종속변수(목표)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "(150, 5)\n",
            "(150, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfXw-QKE5F-X",
        "outputId": "9779825c-1b1c-4481-bcc2-1e81ba8ae907"
      },
      "source": [
        "# 2. 카테고리의 실수화(y를 실수화!)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder # LabelEncoder() method를 불러옴\n",
        "import numpy as np # numpy를 불러옴\n",
        "classle = LabelEncoder()\n",
        "y = classle.fit_transform(iris['species'].values) # species 열의 문자열은 categorial 값으로 전환\n",
        "print('species labels: ' , np.unique(y))\n",
        "\n",
        "#-------------------------------------------------------------------------------#\n",
        "\n",
        "yo = classle.inverse_transform(y) # 원래의 species 문자열로 전환\n",
        "print('species: ' , np.unique(yo))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "species labels:  [0 1 2]\n",
            "species:  ['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu-guFf_8KsW",
        "outputId": "7a345d60-0070-4769-de8c-02a3eecdaa92"
      },
      "source": [
        "# 3. 데이터 분할\n",
        "\n",
        "# 데이터 분할: 학습 데이터(train)와 시험 데이터(test)가 서로 겹치지 않도록 나누는 것\n",
        "# 데이터 분할의 목적: 학습데이터로 학습하고 학습에 전혀 사용하지 않은 시험데이터에 적용해서 학습결과의 일반화(generalization)가 가능한지 알아보기 위함 \n",
        "# 학습 데이터(train)도 나누는 경우가 존재 -> Validation(평가용) : overfitting에 의한 일반화 판별용 \n",
        "# overfitting: 학습 data를 통째로 외워서 새로 들어오는 data에 대한 적응력이 낮은 상태\n",
        "\n",
        "from sklearn.model_selection import train_test_split # Scikit-Learn의 model_selection library를 train_test_split로 명명\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 1, stratify = y) # train:test = 70:30, stratify = y -> 편항 방지\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(105, 4)\n",
            "(45, 4)\n",
            "(105,)\n",
            "(45,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmsVoAB0BgP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3821f51-8623-49e3-dd0f-750b684a51c8"
      },
      "source": [
        "# 4. 모형 추정 및 사례중심 학습\n",
        "\n",
        "# 학습\n",
        "from sklearn.neighbors import KNeighborsClassifier # KNN 불러오기\n",
        "knn = KNeighborsClassifier(n_neighbors=5, p=2) # 5개의 인접한이웃, 거리측정기준: 유클리드(p=2이므로)\n",
        "knn.fit(x_train,y_train) # 모델 fitting과정 -> 학습!\n",
        "\n",
        "#-------------------------------------------------------------------------------#\n",
        "\n",
        "# 예측, 평가\n",
        "y_train_pred = knn.predict(x_train) # train data의 y값 예측치 -> 학습데이터 예측을 통해 틀린 갯수 줄이기\n",
        "y_test_pred = knn.predict(x_test) # 모델을 적용한 test data의 y값 예측치\n",
        "print('Misclassifed training samples: %d' %(y_train!=y_train_pred).sum()) #오분류 학습 데이터 갯수 확인\n",
        "print('Misclassifed training samples: %d' %(y_test!=y_test_pred).sum()) #오분류 테스트 데이터 갯수 확인"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misclassifed training samples: 2\n",
            "Misclassifed training samples: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv91RIpCMgIA",
        "outputId": "4cb84fcc-475d-40c5-c0f2-9acec7436cb9"
      },
      "source": [
        "# 5. 결과 분석\n",
        "\n",
        "# 분류문제는 회귀분석과 달리 다양한 성능 평가 기준(metric)이 필요함 -> ex) confusion_matrix, accuracy_score, precision_score 등등\n",
        "\n",
        "from sklearn.metrics import accuracy_score # 정확도 계산을 위한 모듈 import\n",
        "print(accuracy_score(y_test,y_test_pred)) # 45개 test sample중 45-3 = 42개가 정확하게 분류됨\n",
        "\n",
        "#-------------------------------------------------------------------------------#\n",
        "\n",
        "# 혼합행렬(confusion matrix): 타겟의 원래 클래스와 모형이 예측한 클래스가 일치하는지를 갯수로 센 결과를 표로 나타낸 것 -> 대각 행렬의 갯수가 정답 갯수이다!\n",
        "from sklearn.metrics import confusion_matrix #오분류표 작성을 위한 모듈 import\n",
        "conf = confusion_matrix(y_true = y_test, y_pred = y_test_pred) #대각원소가 각각 setosa, versicolor, virginica를 정확하게 분류한 갯수\n",
        "print(conf)\n",
        "\n",
        "#-------------------------------------------------------------------------------#\n",
        "# 정확도(accuracy): 전체 샘플(양성클래스 + 음성클래스) 중 맞게 예측한 샘플 수의 비율\n",
        "# 정밀도(precision): 양성클래스에 속한다고 예측한 샘플 중 실제로 양성클래스에 속하는 샘플 수의 비율\n",
        "# 재현율(recall): 실제 양성클래스에 속한 표본 중에 양성 클래스에 속한다고 예측한 표본의 수의 비율\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9777777777777777\n",
            "[[15  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  1 14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IIKpmCWP8wa",
        "outputId": "d92e3ee3-4ed9-4ba3-b5c2-87f8ca7823df"
      },
      "source": [
        "# 6. (옵션) 입력데이터의 표준화\n",
        "\n",
        "# 특정 자료의 측정 단위에 의해 영향 받지 않도록 하는 과정\n",
        "# 시험 데이터(test data)의 표준화는 학습 데이터(train data)에서 구한 특성 변수의 평균과 표준편차를 이용함\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler #Scikit-Learn의 model_selection library를 train_test_split로 명명\n",
        "sc = StandardScaler()\n",
        "sc.fit(x_train) # train data에만 fit을 해준다\n",
        "x_train_std = sc.transform(x_train) # training data의 표준화\n",
        "x_test_std = sc.transform(x_test) # test data의 표준화\n",
        "print(x_train.head())\n",
        "print(x_train_std[1:5,])\n",
        "\n",
        "#-------------------------------------------------------------------------------#\n",
        "\n",
        "# KNN의 적용\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5, p=2)\n",
        "knn.fit(x_train_std, y_train)\n",
        "\n",
        "#-------------------------------------------------------------------------------#\n",
        "\n",
        "# 예측, 평가\n",
        "y_train_pred = knn.predict(x_train_std) #train data의 y값 예측치\n",
        "y_test_pred = knn.predict(x_test_std) #모델을 적용한 test data의 y값 예측치\n",
        "print('Misclassifed training samples: %d' %(y_train!=y_train_pred).sum()) #오분류 학습 데이터 갯수 확인\n",
        "print('Misclassifed training samples: %d' %(y_test!=y_test_pred).sum()) #오분류 테스트 데이터 갯수 확인\n",
        "\n",
        "#-------------------------------------------------------------------------------#\n",
        "\n",
        "from sklearn.metrics import accuracy_score #정확도 계산을 위한 모듈 import\n",
        "print(accuracy_score(y_test,y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width\n",
            "33            5.5          4.2           1.4          0.2\n",
            "20            5.4          3.4           1.7          0.2\n",
            "115           6.4          3.2           5.3          2.3\n",
            "124           6.7          3.3           5.7          2.1\n",
            "35            5.0          3.2           1.2          0.2\n",
            "[[-0.55053619  0.76918392 -1.16537974 -1.30728421]\n",
            " [ 0.65376173  0.30368356  0.84243039  1.44587881]\n",
            " [ 1.0150511   0.53643374  1.0655204   1.18367281]\n",
            " [-1.03225536  0.30368356 -1.44424226 -1.30728421]]\n",
            "Misclassifed training samples: 4\n",
            "Misclassifed training samples: 3\n",
            "0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oE5oH6hfIYA"
      },
      "source": [
        "### **Regression(회귀)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM9y053Sfrxy"
      },
      "source": [
        "# KNN 회귀 -> y의 예측치 계산만 다룬다\n",
        "# 단순 회귀: 가까운 이웃들의 단순한 평균을 구하는 방식\n",
        "# 가중 회구: 거리가 가까울수록 데이터가 더 유사할 것이라고 보고 가중치를 부여하는 방식"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFREkWquY4Y9",
        "outputId": "57d45f97-e64b-49d6-b4b6-92a4d0cdc20a"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "regressor = KNeighborsRegressor(n_neighbors=3, weights=\"distance\") # distance는 가중회귀\n",
        "training_points = [ # 정보\n",
        "  [0.5, 0.2, 0.1], # A\n",
        "  [0.9, 0.7, 0.3], # B\n",
        "  [0.4, 0.5, 0.7]  # C\n",
        "]\n",
        "training_labels = [5.0, 6.8, 9.0] # 등급\n",
        "regressor.fit(training_points, training_labels)\n",
        "unknown_points = [\n",
        "  [0.2,0.1,0.7], # A\n",
        "  [0.4,0.7,0.6], # B\n",
        "  [0.5,0.8,0.1]  # C\n",
        "]\n",
        "guesses = regressor.predict(unknown_points)\n",
        "guesses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7.28143288, 7.76451922, 6.8457845 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRQvOkdTb1MM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}